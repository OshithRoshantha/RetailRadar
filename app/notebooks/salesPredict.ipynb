{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('sparkApp').config(\"spark.python.worker.timeout\", \"120\") .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|Product_Category|\n",
      "+----------------+\n",
      "|         Grocery|\n",
      "|     Electronics|\n",
      "|        Clothing|\n",
      "|           Books|\n",
      "|      Home Decor|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"../../data/processed/cleanedData.parquet\")\n",
    "unique_values_df = df.select(\"Product_Category\").distinct()\n",
    "unique_values_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------------+\n",
      "|Product_Category|      Date|Total_Purchases|\n",
      "+----------------+----------+---------------+\n",
      "|           Books|2001-01-24|            747|\n",
      "|        Clothing|2001-01-24|            732|\n",
      "|     Electronics|2001-01-24|           1062|\n",
      "|         Grocery|2001-01-24|            882|\n",
      "|      Home Decor|2001-01-24|            774|\n",
      "|           Books|2001-02-24|            954|\n",
      "|        Clothing|2001-02-24|            733|\n",
      "|     Electronics|2001-02-24|            982|\n",
      "|         Grocery|2001-02-24|            821|\n",
      "|      Home Decor|2001-02-24|            651|\n",
      "|           Books|2001-03-24|            840|\n",
      "|        Clothing|2001-03-24|            838|\n",
      "|     Electronics|2001-03-24|            868|\n",
      "|         Grocery|2001-03-24|            954|\n",
      "|      Home Decor|2001-03-24|            897|\n",
      "|           Books|2001-04-24|            775|\n",
      "|        Clothing|2001-04-24|            743|\n",
      "|     Electronics|2001-04-24|            949|\n",
      "|         Grocery|2001-04-24|            876|\n",
      "|      Home Decor|2001-04-24|            866|\n",
      "|           Books|2001-05-24|            773|\n",
      "|        Clothing|2001-05-24|            771|\n",
      "|     Electronics|2001-05-24|            999|\n",
      "|         Grocery|2001-05-24|            943|\n",
      "|      Home Decor|2001-05-24|            779|\n",
      "|           Books|2001-06-24|            737|\n",
      "|        Clothing|2001-06-24|            705|\n",
      "|     Electronics|2001-06-24|            989|\n",
      "|         Grocery|2001-06-24|            987|\n",
      "|      Home Decor|2001-06-24|            719|\n",
      "|           Books|2001-07-24|            766|\n",
      "|        Clothing|2001-07-24|            628|\n",
      "|     Electronics|2001-07-24|            970|\n",
      "|         Grocery|2001-07-24|            860|\n",
      "|      Home Decor|2001-07-24|            705|\n",
      "|           Books|2001-08-24|            698|\n",
      "|        Clothing|2001-08-24|            622|\n",
      "|     Electronics|2001-08-24|            921|\n",
      "|         Grocery|2001-08-24|            850|\n",
      "|      Home Decor|2001-08-24|            842|\n",
      "|           Books|2001-09-24|            724|\n",
      "|        Clothing|2001-09-24|            826|\n",
      "|     Electronics|2001-09-24|           1003|\n",
      "|         Grocery|2001-09-24|           1022|\n",
      "|      Home Decor|2001-09-24|            743|\n",
      "|           Books|2001-10-24|            854|\n",
      "|        Clothing|2001-10-24|            755|\n",
      "|     Electronics|2001-10-24|            926|\n",
      "|         Grocery|2001-10-24|           1211|\n",
      "|      Home Decor|2001-10-24|            760|\n",
      "+----------------+----------+---------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.groupBy(\"Product_Category\", \"Date\").agg(F.sum(F.col('Total_Purchases')).alias(\"Total_Purchases\")).orderBy(\"Date\", \"Product_Category\")\n",
    "df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"sales_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+---------------+\n",
      "|Product_Category|      Date|Total_Purchases|\n",
      "+----------------+----------+---------------+\n",
      "|         Grocery|2001-01-24|            882|\n",
      "|         Grocery|2001-01-25|              0|\n",
      "|         Grocery|2001-01-26|              0|\n",
      "|         Grocery|2001-01-27|              0|\n",
      "|         Grocery|2001-01-28|              0|\n",
      "|         Grocery|2001-01-29|              0|\n",
      "|         Grocery|2001-01-30|              0|\n",
      "|         Grocery|2001-01-31|              0|\n",
      "|         Grocery|2001-02-01|              0|\n",
      "|         Grocery|2001-02-02|              0|\n",
      "|         Grocery|2001-02-03|              0|\n",
      "|         Grocery|2001-02-04|              0|\n",
      "|         Grocery|2001-02-05|              0|\n",
      "|         Grocery|2001-02-06|              0|\n",
      "|         Grocery|2001-02-07|              0|\n",
      "|         Grocery|2001-02-08|              0|\n",
      "|         Grocery|2001-02-09|              0|\n",
      "|         Grocery|2001-02-10|              0|\n",
      "|         Grocery|2001-02-11|              0|\n",
      "|         Grocery|2001-02-12|              0|\n",
      "+----------------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minMaxDates = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        Product_Category, \n",
    "        MIN(Date) AS min_date, \n",
    "        MAX(Date) AS max_date \n",
    "    FROM sales_data \n",
    "    GROUP BY Product_Category\n",
    "\"\"\")\n",
    "minMaxDates.createOrReplaceTempView(\"minMaxDates\")\n",
    "\n",
    "\n",
    "dateSeries = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        Product_Category, \n",
    "        date_add(min_date, idx) AS Date\n",
    "    FROM (\n",
    "        SELECT \n",
    "            Product_Category, \n",
    "            min_date, \n",
    "            max_date, \n",
    "            posexplode(\n",
    "                split(space(datediff(max_date, min_date)), ' ')\n",
    "            ) AS (idx, _)\n",
    "        FROM minMaxDates\n",
    "    )\n",
    "\"\"\")\n",
    "dateSeries.createOrReplaceTempView(\"dateSeries\")\n",
    "\n",
    "\n",
    "dfFilled = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        ds.Product_Category, \n",
    "        ds.Date, \n",
    "        COALESCE(sd.Total_Purchases, 0) AS Total_Purchases\n",
    "    FROM dateSeries ds\n",
    "    LEFT JOIN sales_data sd\n",
    "    ON ds.Product_Category = sd.Product_Category AND ds.Date = sd.Date\n",
    "\"\"\")\n",
    "dfFilled.createOrReplaceTempView(\"filled_data\")\n",
    "\n",
    "\n",
    "dfFilled.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainProphetModel(dfFilled):\n",
    "    dfFilled['Date'] = pd.to_datetime(dfFilled['Date'])\n",
    "    models = {}\n",
    "    for category in dfFilled['Product_Category'].unique():\n",
    "        categoryData = dfFilled[dfFilled['Product_Category'] == category]\n",
    "        prophetData = categoryData[['Date', 'Total_Purchases']].rename(columns={'Date': 'ds', 'Total_Purchases': 'y'})\n",
    "        model = Prophet()\n",
    "        model.fit(prophetData)\n",
    "        models[category] = model\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNext30Days(models, dfFilled):\n",
    "    dfFilled['Date'] = pd.to_datetime(dfFilled['Date'])\n",
    "    predictions = {}\n",
    "    for category, model in models.items():\n",
    "        categoryData = dfFilled[dfFilled['Product_Category'] == category]\n",
    "        prophetData = categoryData[['Date', 'Total_Purchases']].rename(columns={'Date': 'ds', 'Total_Purchases': 'y'})\n",
    "        lastDate = prophetData['ds'].max()\n",
    "        future = model.make_future_dataframe(periods=30, include_history=False)\n",
    "        future = future[future['ds'] > lastDate]\n",
    "        forecast = model.predict(future)\n",
    "        predictions[category] = forecast[['ds', 'yhat']].assign(Product_Category=category)\n",
    "    allPredictions = pd.concat(predictions.values())\n",
    "    totalSales = allPredictions.groupby('Product_Category')['yhat'].sum().reset_index()\n",
    "    totalSales.columns = ['Product_Category', 'Total_Predicted_Sales']\n",
    "    return allPredictions, totalSales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:32:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:32:47 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:32:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:32:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:32:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:32:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:32:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:32:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:32:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:32:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Product_Category  Total_Predicted_Sales\n",
      "0            Books            9325.399123\n",
      "1         Clothing            9218.462101\n",
      "2      Electronics           11999.799691\n",
      "3          Grocery           11003.799034\n",
      "4       Home Decor            9121.143987\n"
     ]
    }
   ],
   "source": [
    "dfFilled = dfFilled.toPandas()\n",
    "models = trainProphetModel(dfFilled)\n",
    "predictions, totalSales = predictNext30Days(models, dfFilled)\n",
    "\n",
    "print(totalSales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
